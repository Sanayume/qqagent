"""
æ¶ˆæ¯èšåˆå™¨ - ç¾¤èŠæ¶ˆæ¯é˜²æŠ–å’Œèšåˆ

åŠŸèƒ½ï¼š
- ç¾¤èŠä¸­ç¬¬ä¸€æ¡æ¶ˆæ¯åˆ°è¾¾æ—¶ï¼Œå¯åŠ¨ 5 ç§’ç­‰å¾…
- å¦‚æœ 5 ç§’å†…æœ‰æ–°æ¶ˆæ¯ï¼Œå»¶é•¿ç­‰å¾…åˆ° 10 ç§’
- è¶…æ—¶åå°†æ‰€æœ‰æ¶ˆæ¯èšåˆï¼Œä¸€æ¬¡æ€§å‘ç»™ Agent

è¿™æ ·åšçš„å¥½å¤„ï¼š
- é¿å…ç”¨æˆ·è¿ç»­å‘æ¶ˆæ¯æ—¶æœºå™¨äººé¢‘ç¹å“åº”
- è®© Agent çœ‹åˆ°å®Œæ•´çš„å¯¹è¯ä¸Šä¸‹æ–‡
"""

import asyncio
import time
from dataclasses import dataclass, field
from typing import Callable, Coroutine, Any

from src.utils.logger import log


@dataclass
class PendingMessage:
    """å¾…èšåˆçš„å•æ¡æ¶ˆæ¯"""
    sender_name: str
    sender_qq: int
    message_id: int
    text: str
    image_urls: list[str] = field(default_factory=list)
    reply_context: str | None = None  # å¼•ç”¨æ¶ˆæ¯çš„å†…å®¹
    reply_to_id: int | None = None    # å¼•ç”¨çš„æ¶ˆæ¯ ID
    at_targets: list[str] = field(default_factory=list)
    forward_summary: str | None = None
    timestamp: float = field(default_factory=time.time)

    def format(self) -> str:
        """æ ¼å¼åŒ–ä¸ºå¯è¯»æ–‡æœ¬"""
        parts = []

        # å‘é€è€…ä¿¡æ¯
        header = f"ã€{self.sender_name} (QQ:{self.sender_qq})ã€‘"

        # å¼•ç”¨ä¿¡æ¯
        if self.reply_context:
            if self.reply_to_id:
                parts.append(f"â†©ï¸ å¼•ç”¨æ¶ˆæ¯ID {self.reply_to_id}: ã€Œ{self.reply_context}ã€")
            else:
                parts.append(f"â†©ï¸ å¼•ç”¨: ã€Œ{self.reply_context}ã€")

        # æ¶ˆæ¯æ­£æ–‡
        if self.text:
            parts.append(self.text)
        elif self.image_urls:
            parts.append(f"[å‘é€äº† {len(self.image_urls)} å¼ å›¾ç‰‡]")

        # @ ç›®æ ‡
        if self.at_targets:
            parts.append(f"(@äº†: {', '.join(self.at_targets)})")

        # è½¬å‘æ‘˜è¦
        if self.forward_summary:
            # è½¬å‘å†…å®¹è¾ƒé•¿ï¼Œå•ç‹¬ä¸€æ®µ
            parts.append(f"[è½¬å‘æ¶ˆæ¯]\n{self.forward_summary}")

        content = "\n".join(parts) if parts else "(ç©ºæ¶ˆæ¯)"
        return f"{header}\n{content}"


@dataclass
class AggregationBucket:
    """å•ä¸ªç¾¤çš„æ¶ˆæ¯èšåˆæ¡¶"""
    group_id: int
    messages: list[PendingMessage] = field(default_factory=list)
    first_message_time: float = 0
    last_message_time: float = 0
    timer_task: asyncio.Task | None = None
    # ä¿å­˜åŸå§‹äº‹ä»¶ï¼Œç”¨äºå›å¤
    first_event: Any = None


class MessageAggregator:
    """
    æ¶ˆæ¯èšåˆå™¨

    ä½¿ç”¨æ–¹å¼ï¼š
        aggregator = MessageAggregator(
            initial_wait=5.0,
            extended_wait=10.0,
            on_aggregate=handle_aggregated_messages,
        )

        # åœ¨æ¶ˆæ¯å¤„ç†å™¨ä¸­
        await aggregator.add_message(group_id, pending_msg, event)

    å‚æ•°ï¼š
        initial_wait: é¦–æ¬¡æ¶ˆæ¯åçš„ç­‰å¾…æ—¶é—´ (ç§’)
        extended_wait: æœ‰åç»­æ¶ˆæ¯æ—¶çš„æœ€å¤§ç­‰å¾…æ—¶é—´ (ç§’)
        on_aggregate: èšåˆå®Œæˆåçš„å›è°ƒå‡½æ•°
    """

    def __init__(
        self,
        initial_wait: float = 5.0,
        extended_wait: float = 10.0,
        on_aggregate: Callable[[int, list[PendingMessage], Any], Coroutine[Any, Any, None]] | None = None,
    ):
        self.initial_wait = initial_wait
        self.extended_wait = extended_wait
        self.on_aggregate = on_aggregate

        # group_id -> AggregationBucket
        self._buckets: dict[int, AggregationBucket] = {}
        self._lock = asyncio.Lock()

    async def add_message(
        self,
        group_id: int,
        message: PendingMessage,
        event: Any = None,
    ) -> bool:
        """
        æ·»åŠ æ¶ˆæ¯åˆ°èšåˆæ¡¶

        Args:
            group_id: ç¾¤å·
            message: å¾…èšåˆçš„æ¶ˆæ¯
            event: åŸå§‹äº‹ä»¶å¯¹è±¡ï¼ˆç”¨äºåç»­å›å¤ï¼‰

        Returns:
            True å¦‚æœæ˜¯æ–°çš„èšåˆï¼ˆé¦–æ¡æ¶ˆæ¯ï¼‰
            False å¦‚æœæ˜¯è¿½åŠ åˆ°ç°æœ‰èšåˆ
        """
        async with self._lock:
            now = time.time()
            is_first = False

            if group_id not in self._buckets:
                # æ–°çš„èšåˆæ¡¶
                bucket = AggregationBucket(
                    group_id=group_id,
                    first_message_time=now,
                    first_event=event,
                )
                self._buckets[group_id] = bucket
                is_first = True
                log.info(f"ğŸ“¥ ç¾¤ {group_id}: å¼€å§‹æ¶ˆæ¯èšåˆï¼Œç­‰å¾… {self.initial_wait}s")
            else:
                bucket = self._buckets[group_id]

            # æ·»åŠ æ¶ˆæ¯
            bucket.messages.append(message)
            bucket.last_message_time = now

            # è®¡ç®—ç­‰å¾…æ—¶é—´
            elapsed = now - bucket.first_message_time
            if is_first:
                # é¦–æ¡æ¶ˆæ¯ï¼šç­‰å¾… initial_wait
                wait_time = self.initial_wait
            else:
                # åç»­æ¶ˆæ¯ï¼šå»¶é•¿åˆ° extended_waitï¼Œä½†ä¸è¶…è¿‡å‰©ä½™æ—¶é—´
                remaining = self.extended_wait - elapsed
                wait_time = max(0.5, remaining)  # è‡³å°‘ç­‰ 0.5s
                log.debug(f"ğŸ“¥ ç¾¤ {group_id}: è¿½åŠ æ¶ˆæ¯ï¼Œå‰©ä½™ç­‰å¾… {wait_time:.1f}s")

            # å–æ¶ˆæ—§å®šæ—¶å™¨
            if bucket.timer_task and not bucket.timer_task.done():
                bucket.timer_task.cancel()

            # å¯åŠ¨æ–°å®šæ—¶å™¨
            bucket.timer_task = asyncio.create_task(
                self._wait_and_flush(group_id, wait_time)
            )

            return is_first

    async def _wait_and_flush(self, group_id: int, wait_time: float):
        """ç­‰å¾…åè§¦å‘èšåˆ"""
        try:
            await asyncio.sleep(wait_time)
            await self._flush(group_id)
        except asyncio.CancelledError:
            # å®šæ—¶å™¨è¢«å–æ¶ˆï¼ˆæœ‰æ–°æ¶ˆæ¯åˆ°è¾¾ï¼‰
            pass

    async def _flush(self, group_id: int):
        """è§¦å‘èšåˆå›è°ƒ"""
        async with self._lock:
            bucket = self._buckets.pop(group_id, None)

        if not bucket or not bucket.messages:
            return

        log.info(f"ğŸ“¤ ç¾¤ {group_id}: èšåˆå®Œæˆï¼Œå…± {len(bucket.messages)} æ¡æ¶ˆæ¯")

        if self.on_aggregate:
            try:
                await self.on_aggregate(group_id, bucket.messages, bucket.first_event)
            except Exception as e:
                log.error(f"èšåˆå›è°ƒå¤±è´¥: {e}")

    async def flush_all(self):
        """å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰æ¡¶ï¼ˆç”¨äºå…³é—­æ—¶ï¼‰"""
        async with self._lock:
            group_ids = list(self._buckets.keys())

        for group_id in group_ids:
            await self._flush(group_id)

    def get_pending_count(self, group_id: int) -> int:
        """è·å–ç¾¤çš„å¾…å¤„ç†æ¶ˆæ¯æ•°"""
        bucket = self._buckets.get(group_id)
        return len(bucket.messages) if bucket else 0

    def is_aggregating(self, group_id: int) -> bool:
        """æ£€æŸ¥ç¾¤æ˜¯å¦æ­£åœ¨èšåˆä¸­"""
        return group_id in self._buckets


def format_aggregated_messages(
    messages: list[PendingMessage],
    group_id: int,
) -> str:
    """
    æ ¼å¼åŒ–èšåˆåçš„æ¶ˆæ¯ä¸º LLM å¯è¯»çš„æ–‡æœ¬

    Args:
        messages: èšåˆçš„æ¶ˆæ¯åˆ—è¡¨
        group_id: ç¾¤å·

    Returns:
        æ ¼å¼åŒ–çš„æ–‡æœ¬

    Example output:
        [ç¾¤èŠæ¶ˆæ¯æ±‡æ€»]
        ç¾¤å·: 123456
        æ¶ˆæ¯æ•°: 3
        æ—¶é—´è·¨åº¦: 8.2 ç§’

        ---
        ã€å¼ ä¸‰ (QQ:111111)ã€‘
        ä½ å¥½å•Š

        ---
        ã€æå›› (QQ:222222)ã€‘
        â†©ï¸ å¼•ç”¨: ã€Œä½ å¥½å•Šã€
        åœ¨å—ï¼Ÿ

        ---
        ã€å¼ ä¸‰ (QQ:111111)ã€‘
        [å‘é€äº† 1 å¼ å›¾ç‰‡]
    """
    if not messages:
        return "[æ— æ¶ˆæ¯]"

    # è®¡ç®—æ—¶é—´è·¨åº¦
    first_time = messages[0].timestamp
    last_time = messages[-1].timestamp
    time_span = last_time - first_time

    parts = []

    # å¤´éƒ¨ä¿¡æ¯
    header_lines = [
        "[ç¾¤èŠæ¶ˆæ¯æ±‡æ€»]",
        f"ç¾¤å·: {group_id}",
        f"æ¶ˆæ¯æ•°: {len(messages)}",
    ]
    if time_span > 0.1:
        header_lines.append(f"æ—¶é—´è·¨åº¦: {time_span:.1f} ç§’")

    parts.append("\n".join(header_lines))

    # æ¯æ¡æ¶ˆæ¯
    for msg in messages:
        parts.append("---")
        parts.append(msg.format())

    return "\n\n".join(parts)


def collect_images_from_messages(messages: list[PendingMessage]) -> list[str]:
    """ä»èšåˆæ¶ˆæ¯ä¸­æ”¶é›†æ‰€æœ‰å›¾ç‰‡ URL"""
    urls = []
    for msg in messages:
        urls.extend(msg.image_urls)
    return urls
